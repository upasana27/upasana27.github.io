<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Do Cognitively Interpretable Reasoning Traces Improve LLM Performance? - Upasana Biswas</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>

<body>

<nav class="navbar">
    <div class="container">
        <div class="nav-brand">Upasana Biswas</div>
        <ul class="nav-menu">
            <li><a href="index.html">Home</a></li>
            <li><a href="index.html#about">About</a></li>
            <li><a href="index.html#research">Research</a></li>
            <li><a href="index.html#publications">Publications</a></li>
            <li><a href="index.html#talks">Talks</a></li>
            <li><a href="index.html#teaching">Teaching</a></li>
            <li><a href="index.html#contact">Contact</a></li>
        </ul>
    </div>
</nav>

<main>

<section class="section">
    <div class="container">
        <h1>Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?</h1>
        
        <p><em>August 2025 – December 2025</em></p>
        
        <div class="project-details">

            <h2>Overview</h2>
            <p>
            This work investigates whether reasoning traces that are <strong>cognitively interpretable</strong> 
            — i.e., structured in ways that align with human reasoning processes — actually improve 
            large language model (LLM) performance. While chain-of-thought prompting has been shown 
            to enhance reasoning accuracy, it remains unclear whether human-like interpretability 
            itself contributes to performance gains or merely improves explanation quality.
            </p>

            <h2>Motivation</h2>
            <p>
            Recent advances in LLM reasoning emphasize longer and more explicit reasoning traces. 
            However, the field often assumes that making these traces interpretable to humans 
            improves model reasoning. We question this assumption: does cognitive interpretability 
            causally improve task performance, or are improvements driven by other factors such as 
            token length, intermediate supervision, or implicit computation?
            </p>

            <h2>Approach</h2>
            <p>
            We design controlled experiments comparing different types of reasoning traces: 
            cognitively structured explanations, minimally structured traces, and performance-optimized 
            reasoning formats. By isolating structural interpretability from other variables, 
            we evaluate how reasoning style affects downstream task accuracy across multiple benchmarks.
            </p>

            <h2>Key Contributions</h2>
            <ul>
                <li>Systematic evaluation of cognitively interpretable reasoning traces versus alternative reasoning formats.</li>
                <li>Empirical analysis disentangling interpretability from performance gains in chain-of-thought prompting.</li>
                <li>Insights into when and why structured reasoning traces improve (or fail to improve) LLM accuracy.</li>
            </ul>

            <h2>Results</h2>
            <p>
            Our findings suggest that performance gains are not solely attributable to cognitive 
            interpretability. While structured reasoning can aid certain tasks, improvements often 
            depend on factors such as task type and reasoning decomposition. These results highlight 
            the need to distinguish between explanations that are human-interpretable and those that 
            genuinely enhance model computation.
            </p>

            <h2>Publications</h2>
            <p>
                <strong>Presented at the NeurIPS 2025 Workshop on Cognitive Interpretability (CogInterp)</strong>.
            </p>
            <p>
                <a href="https://arxiv.org/abs/2508.16695" target="_blank">arXiv Paper</a>
            </p>

            <h2>Resources</h2>
            <p>
            Code and experimental materials will be made available. 
            Please reach out for collaboration or further details.
            </p>

        </div>

        <div style="margin-top: 2rem;">
            <a href="index.html#research" class="back-link">← Back to Research</a>
        </div>
    </div>
</section>

</main>

<footer>
    <div class="container">
        <p>&copy; 2026 Upasana Biswas</p>
    </div>
</footer>

<script src="script.js"></script>

</body>
</html>
